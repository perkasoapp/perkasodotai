Perkaso — Parent Safety Guide for Kids Using AI Tools



Who this guide is for: parents and guardians of K–12 kids who want to let their children explore AI tools safely.

Goal: help you evaluate apps, set sensible rules, protect privacy, and encourage healthy learning.



**What to do first**



Decide the age-appropriate guardrails for your child (see age groups below).



Test every app first (create a throwaway account and try it for 10–20 minutes).



Use parental controls + account rules (DOB gating, screen time, content filters).



Talk about safety — set expectations and review what they do online weekly.



Use Perkaso to find tools that are marked safe for kids and read our short reviews on popular AI tools.



**1) How we think about “safe”**



At Perkaso we evaluate tools on four child-safety criteria:



Privacy Protection — Does the app collect minimal data and protect children’s info?



Content Appropriateness — Will the content be age-appropriate and moderated?



Educational Value — Is it genuinely useful for learning or creativity?



Parental Controls — Can parents monitor or limit use easily?



A tool that scores well on all four is a good candidate for supervised or independent use depending on your kid’s age.



**2) Age-based guidance**



Use these simple rules by age — interpret them conservatively and adapt to your child.



Kindergarten (Ages 4–6)



What to allow: supervised educational apps with no chat, strong curation (story-readers, drawing apps, simple language games).



Avoid: any app with open chat, image-generation with public galleries, or unmoderated sharing.



Monitoring: sit with them occasionally, review what they made together.



Elementary (Ages 6–11)



What to allow: guided creative tools (drawing, story generation with parental review), edtech apps designed for children (math, reading).



Avoid: unsupervised LLM chatbots, voice/face apps that share images publicly, or tools that request a lot of personal info.



Monitoring: accounts in parent name when possible; weekly review; set screen-time limits.



Middle School (Ages 11–14)



What to allow: more advanced learning tools, supervised LLM assistants for homework (with parental guidance), creative image apps with filters on content.



Avoid: tools that enable voice cloning, deepfake video generation, or open social features with strangers.



Monitoring: account settings, activity reports, and open dialogue about what they ask the AI.



High School (Ages 14–18)



What to allow: many adult tools with guidance on privacy, copyright, and critical thinking. Teach source vetting.



Avoid: anything that facilitates impersonation, cheating, or unmoderated contact with strangers.



Monitoring: transition toward guidance and conversations about ethics; set boundaries rather than micromanage.



**3) How to test an app before you give it to your child (5-step test)**



Sign up as a parent — create an account and explore the full app for 10–20 minutes.



Check data collection — read the privacy summary and look for required fields like full name, DOB, school name, or pictures. Ask: do they require more than an email?



Try core features — generate content or start a chat and test for unsafe or biased outputs. See what moderation or “report” options exist.



Look for parental tools — can you disable sharing, make the account private, or get usage reports?



Decide \& document — make a short note about rules: “Allowed: practice mode only / Not allowed: image sharing.”



If the app fails one or more steps, consider it unsuitable until changes are made.



**4) Practical settings to apply (simple checklist)**



✅ Create accounts in your name where possible.



✅ Enable device-level parental controls (Apple Screen Time, Google Family Link).



✅ Turn off location sharing and automatic backups for kid accounts.



✅ If the tool has sharing/public gallery features, set uploads to private.



✅ Turn on two-factor authentication for parent accounts.



✅ Regularly export or view activity logs where available.



✅ Use a password manager to create strong, separate passwords.



**5) Privacy \& COPPA basics (what you should know!)**



COPPA (U.S.) protects kids under 13 — it requires verifiable parental consent for collecting personal info. If an app targets young kids and collects personal data, it should offer a clear parental consent flow.



Minimize personal data: avoid apps that require exact DOB, full address, or school details unless you trust the service and it’s essential.



Don’t upload sensitive photos of your child to any public AI gallery. Treat voice samples, schoolwork, or family photos as private.



Third-party processors: read or ask about where data is stored (cloud host) and whether the vendor has a DPA (data processing agreement) in place.



**6) Conversation starters — how to talk to your child**



“What did you ask the app today?” (Encourages transparency.)



“Where did that picture come from?” (Teaches attribution.)



“How would you check whether that answer is true?” (Builds critical thinking.)



“If something made you uncomfortable, please let me know me right away.” (Safety/communication.)



For younger kids, role-play: you ask the AI a silly question and discuss the answer together.



**7) Red flags (STOP and don’t let your child use)**



App encourages sharing personal contact info or location.



App has public galleries where uploads are visible by default.



App offers voice or face cloning features without safety controls.



App chatbots produce hateful, sexual, or violent content on simple prompts.



Company has no clear privacy policy or no child-data rules.



If you see these, discontinue use and report the app to the platform/store where it’s listed.



**8) Tools \& controls you should set up** 



Device controls: Apple Screen Time, Google Family Link (set up daily limits, downtime).



Content filters \& monitoring: Net Nanny, Qustodio, Bark (monitor messaging and flag risky content).



Account protection: use parental email for signups, 2FA on parent account.



Education tools: Prefer kid-focused vendors (Khan Academy, Osmo, Scratch) with explicit child-safety design.



(Specific product steps vary; check the vendor’s help pages for exact instructions.)



**9) A short parental checklist**



&nbsp;I tested the app first as a parent.



&nbsp;The app does not require unnecessary personal data.



&nbsp;Sharing options are set to private.



&nbsp;Screen time \& usage limits are set.



&nbsp;I reviewed the app’s Privacy Policy.



&nbsp;I scheduled a weekly check-in about online use.



&nbsp;I saved receipts and affiliation disclosures for any purchases/affiliates.



**10) How Perkaso helps**



Search by age — use Perkaso filters to find tools rated for your child’s age.



Read our safety label — each tool has a short safety summary and a 4-criteria score.



Use Perky’s Pick — our featured, high-safety tools for quick choices.



Report a problem — if you find a risky tool, use the “Report” button so we can review and update the listing.



**11) Sample Parent-to-School / Consent email (copy \& paste)**



Subject: Quick question about classroom tech tools



Hi \[Teacher Name],



I’m \[Your Name], parent of \[Child Name] in \[Class]. We use Perkaso (perkaso.ai) to evaluate AI learning tools. Before \[App Name] is used in class / or before \[Child Name] uses it at home, could you share whether the district/school has reviewed its privacy and child-safety policies? I’d like to ensure parental consent is handled correctly.



Thanks,

\[Your Name]

\[Contact info]



**12) What to do if something goes wrong**



Stop access — ban the app from the device immediately.



Collect info — save screenshots, URLs, and account names.



Contact the vendor — ask for account deletion and data removal.



Contact Perkaso — report the issue and we’ll mark the tool as “Under Review.”



If there’s a safety/legal issue (e.g., sexual content or grooming), contact local authorities and file a report with the platform/store (Google Play/App Store) and your local consumer protection agency.



**13) FAQ** 



Q: Do I need to block all AI tools?

A: No. Many AI tools are safe and extremely helpful with proper supervision and settings. The goal is informed use, not fear.



Q: Can AI tools replace teachers?

A: No — they are helpers. The best outcomes happen when kids use AI with adult guidance and human instruction.



Q: How often should I review my child’s activity?

A: Weekly quick checks, deeper reviews monthly. Increase checks if you notice behavior or content concerns.



**14) Additional resources (where to learn more)**



Perkaso directory reviews and safety labels (perkaso.ai)



Vendor privacy \& parent pages (check each app’s settings)



Government resources on children’s online safety (search your country’s consumer protection / education department for guidance)



Kid tech safety nonprofits and parenting groups (e.g., local PTA resources)

